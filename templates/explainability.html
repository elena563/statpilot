{% extends "layout.html" %}

{% block main %}

    <main class="relative overflow-hidden pt-4 bg-white">
        <div class="bg-white flex flex-col items-center w-full px-4 sm:px-6 lg:px-8 pb-6 pt-20">
            <div class="w-16 h-16 rounded-xl gradient-purple flex items-center justify-center mb-4">
                <svg viewBox="-7 -7 39.00 39.00" fill="none" xmlns="http://www.w3.org/2000/svg" stroke="#ffffff"><g id="SVGRepo_bgCarrier" stroke-width="0"></g><g id="SVGRepo_tracerCarrier" stroke-linecap="round" stroke-linejoin="round"></g>
                    <g id="SVGRepo_iconCarrier"> <path d="M19.0006 9.03002C19.0007 8.10058 18.8158 7.18037 18.4565 6.32317C18.0972 5.46598 17.5709 4.68895 16.9081 4.03734C16.2453 3.38574 15.4594 2.87265 14.5962 2.52801C13.7331 2.18336 12.8099 2.01409 11.8806 2.03002C10.0966 2.08307 8.39798 2.80604 7.12302 4.05504C5.84807 5.30405 5.0903 6.98746 5.00059 8.77001C4.95795 9.9595 5.21931 11.1402 5.75999 12.2006C6.30067 13.2609 7.10281 14.1659 8.09058 14.83C8.36897 15.011 8.59791 15.2584 8.75678 15.5499C8.91565 15.8415 8.99945 16.168 9.00059 16.5V18.03H15.0006V16.5C15.0006 16.1689 15.0829 15.843 15.24 15.5515C15.3971 15.26 15.6241 15.0121 15.9006 14.83C16.8528 14.1911 17.6336 13.328 18.1741 12.3167C18.7147 11.3054 18.9985 10.1767 19.0006 9.03002V9.03002Z"
                         stroke="#ffffff" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path> <path d="M15 21.04C14.1345 21.6891 13.0819 22.04 12 22.04C10.9181 22.04 9.86548 21.6891 9 21.04" stroke="#ffffff" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path> </g></svg>
            </div>
            <h2 class="text-3xl font-bold text-center tech-dark-purple mb-12">Model Explainability</h2>
            <p class="text-l md:text-l text-gray-600 max-w-3xl mx-auto mb-8 animate-fade-in" style="animation-delay: 0.2s;">
                This page helps you understand how your trained machine learning model makes decisions by visualizing feature importance and generating explanations.
                This is especially useful for building trust in your models and identifying potential biases or unexpected patterns.
                Upload a trained model and the corresponding dataset used to train it. The system will use techniques like SHAP to show which features influenced predictions the most.
                Then you can ask local explanation for one specific observation in your data.
            </p>
        </div>
        <form class='flex flex-col align-center mx-auto mb-6 max-w-xs gap-4' method="POST" enctype="multipart/form-data">
            <input type="hidden" name="form_type" value="global_form">
            <input type="hidden" name="session_id" value="{{ session_id }}">
            <label for="dataset">Upload your X test set (.csv):</label>
            <input type="file" name="xtest" id="xtest" required>

            <label for="model">Upload your model (.pkl):</label>
            <input type="file" name="model" id="model" required>
            <button type="submit" class="bg-purple-500 hover:bg-purple-600 text-white px-8 py-2 rounded-md font-medium">Explain</button>
        </form>
    </main>
    <div class="flex justify-center my-6">
        <div class="loader hidden" id="spinner"></div>
    </div>

    {% if error %}
            <p style="color:red">{{ error }}</p>
    {% endif %}

    {% if summary_plot %}
        <section class="my-6 flex flex-col items-center">
            <h3 class="text-2xl font-bold text-center my-4">Global Variable Importance</h3>
            <p class="max-w-3xl mb-4">The global SHAP summary plot displays the overall importance and impact of each feature 
                across the entire dataset. Each point represents a sample's SHAP value for a given 
                feature, showing how much that feature influenced the model's output for that instance. 
                The position on the x-axis shows whether the feature pushed the prediction higher 
                (positive SHAP value) or lower (negative SHAP value). The color typically represents the
                 feature value (e.g., red for high, blue for low). This plot helps identify which features 
                 have the strongest influence on model decisions in general.</p>
            <img src="{{ summary_plot }}" width="500">
        </section>
        <section class="bg-white my-8 py-6">
            <h3 class="text-2xl font-bold text-center my-4">Local Explanation</h3>
            <form class='flex flex-col align-center mx-auto mb-6 max-w-xs gap-4' method="POST" enctype="multipart/form-data">
                <input type="hidden" name="form_type" value="local_form">
                <input type="hidden" name="session_id" value="{{ session_id }}">
                <label for="obs">Insert the index corresponding your observation:</label>
                <input class="input-cont" type="number" name="obs" id="obs" required>
                <button type="submit" class="bg-purple-500 hover:bg-purple-600 text-white px-8 py-2 rounded-md font-medium">Explain</button>
            </form>
        </section>
    {% endif %}

    {% if plots %}
        <section class="my-6 flex flex-col items-center relative">
            <h3 class="text-2xl font-bold text-center my-4">Local Variable Explanation</h3>
            <div style="overflow-x: auto; max-width: 90%;">
                <table class="max-w-3xl">
                    <thead>
                        {% for name in feature_names %}
                            <th class="p-4 border-b border-gray-100 bg-gray-200">{{ name }}</th>
                        {% endfor %}
                        <th class="p-4 border-b border-gray-100 bg-gray-200">Predicted Class/Value</th>
                    </thead>
                    {% for value in row_list %}
                        <td class="p-4 border-b border-gray-100 bg-white">
                            {% if value is number %}
                                {{ value|round(3) }}
                            {% else %}
                                {{ value }}
                            {% endif %}
                        </td>
                    {% endfor %}
                    <td class="p-4 border-b border-gray-100 bg-white">
                        {% if y_pred2 is number %}
                            {{ y_pred2|round(3) }}
                        {% else %}
                            {{ y_pred2 }}
                        {% endif %}
                    </td>
                </table>
            </div>
            <p class="max-w-3xl my-6">Local SHAP plots explain the prediction for a single instance by showing how each feature 
                contributes to pushing the model output from the baseline (average prediction) to the final 
                predicted value. For example, the force plot uses arrows and colors to illustrate positive 
                and negative contributions, making it easy to see why the model made a specific prediction. 
                The waterfall plot breaks down the effect of each feature step-by-step. These local 
                explanations are useful for understanding individual predictions in detail and for 
                communicating model decisions to end users.</p>
            {% for plot in plots %}
                <img src="{{ plot }}" width="500">
            {% endfor %}

        </section>
    {% endif %}

{% endblock %}