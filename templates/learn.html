{% extends "layout.html" %}

{% block main %}

    <main class="relative overflow-hidden bg-gradient-to-b from-gray-100 to-white pt-12 mb-8">
        <div class="bg-white w-full px-4 sm:px-10 lg:px-8 py-20 md:py-20">
            <div class="text-center">
                <h2 class="text-3xl font-bold tech-dark-purple mb-6 animate-fade-in">
                    Discover what's behind!
                </h2>
                <p class="text-m md:text-m text-gray-600 max-w-3xl mx-auto animate-fade-in" style="animation-delay: 0.2s;">
                    In this page, you can find some info to get deeper with your knowledge of data analysis, machine learning, and explainable AI.
                </p>
            </div>
        </div>
    </main>

    <section class="my-6 flex flex-col items-center max-w-[90%] mx-auto">
        <h3 class="text-2xl font-bold text-center my-4">Data Analysis</h3>
        <p class="text-s md:text-s max-w-4xl mx-auto">Data analysis, at its core, is the process of inspecting, cleansing, transforming, and modeling data with the goal of discovering useful information, informing conclusions, and supporting decision-making. In an era where data is generated at an unprecedented pace – from financial transactions and social media interactions to scientific experiments and sensor readings – the ability to extract meaningful insights from this deluge has become a critical skill for businesses, researchers, and policymakers alike. It's more than just crunching numbers; it's about storytelling with data, identifying patterns, uncovering anomalies, and predicting future trends.</p>
        <br/><p class="text-s md:text-s max-w-4xl mx-auto">The journey of data analysis typically begins with data collection, which can involve various methods depending on the source, such as web scraping, database queries, API integrations, or manual entry. This raw data is often messy, incomplete, and inconsistent, necessitating a crucial step known as data cleaning or wrangling. This involves handling missing values, correcting errors, removing duplicates, and standardizing formats to ensure data quality and reliability. Without clean data, any subsequent analysis risks producing misleading or inaccurate results.</p>
        <br/><p class="text-s md:text-s max-w-4xl mx-auto">Once the data is clean, exploratory data analysis (EDA) comes into play. EDA uses statistical summaries and graphical representations – like histograms, scatter plots, box plots, and heatmaps – to visualize the data's structure, identify relationships between variables, detect outliers, and gain initial insights. This phase is iterative and highly interactive, guiding the analyst to formulate hypotheses and select appropriate analytical techniques. For instance, a scatter plot might reveal a strong correlation between two variables, suggesting a potential causal link that warrants further investigation.</p>
        <img src="/static/images/analysis.png" alt="data analysis illustration" width="270">
        <br/><p class="text-s md:text-s max-w-4xl mx-auto">Beyond exploration, data analysis encompasses a wide array of techniques, broadly categorized into descriptive, diagnostic, predictive, and prescriptive analytics. Descriptive analytics focuses on summarizing past events and trends, answering "what happened?" For example, calculating average sales figures or identifying the most popular products in a given period. Diagnostic analytics delves deeper, seeking to understand "why did it happen?" This often involves root cause analysis, drilling down into specific data points to uncover the underlying reasons for observed phenomena.</p>
        <br/><p class="text-s md:text-s max-w-4xl mx-auto">Predictive analytics, perhaps the most sought-after form, aims to forecast future outcomes based on historical data, answering "what will happen?" This is where statistical modeling, regression analysis, and time series forecasting come into their own. For example, predicting customer churn, stock prices, or disease outbreaks. Finally, prescriptive analytics takes it a step further, suggesting optimal courses of action to influence future outcomes, answering "what should I do?" This often involves optimization algorithms and simulation models to recommend specific strategies, such as optimizing supply chains or personalizing marketing campaigns.</p>
        <br/><p class="text-s md:text-s max-w-4xl mx-auto">The tools employed in data analysis are diverse, ranging from powerful programming languages like Python (with libraries such as Pandas, NumPy, Matplotlib, and Seaborn) and R, to specialized statistical software like SAS and SPSS, and user-friendly business intelligence (BI) tools like Tableau and Power BI. The choice of tool often depends on the complexity of the analysis, the size of the dataset, and the analyst's skill set.</p>
        <a href='/analyze' class="bg-purple-500 hover:bg-purple-600 text-white px-8 py-2 my-8 rounded-md font-medium">Try Data Analysis</a>
    </section>
    <section class="bg-white my-10 flex flex-col items-center max-w-full px-auto">
        <h3 class="text-2xl font-bold text-center mt-8 mb-4">Machine Learning</h3>
        <p class="text-s md:text-s max-w-[min(56rem,90%)] mx-auto">Machine Learning (ML) is a subfield of artificial intelligence (AI) that focuses on enabling systems to learn from data without being explicitly programmed. Instead of following pre-defined rules, ML algorithms identify patterns and relationships within vast datasets, using these insights to make predictions or decisions. This paradigm shift from rule-based programming to data-driven learning has unlocked unprecedented capabilities across numerous domains, from image recognition and natural language processing to medical diagnosis and autonomous driving.</p>
        <br/><p class="text-s md:text-s max-w-[min(56rem,90%)] mx-auto">The fundamental principle behind machine learning is that algorithms can "learn" from examples. This learning process typically falls into three main categories: supervised learning, unsupervised learning, and reinforcement learning.</p>
        <br/><p class="text-s md:text-s max-w-[min(56rem,90%)] mx-auto">Unsupervised learning, deals with unlabeled data. The algorithms aim to discover hidden patterns, structures, or relationships within the data without any prior knowledge of the output.<br/>Reinforcement learning (RL) involves an agent learning to make decisions by interacting with an environment. The agent receives rewards or penalties based on its actions, and its goal is to learn a policy that maximizes the cumulative reward over time. RL is particularly suited for tasks where sequential decision-making is crucial, such as robotics, game playing (e.g., AlphaGo), and autonomous navigation.</p>
        <img src="/static/images/ml.png" alt="reinforcement learning illustration" width="270">
        <br/><p class="text-s md:text-s max-w-[min(56rem,90%)] mx-auto">Supervised learning is the most common type, where the algorithm is trained on a labeled dataset, meaning each input example is paired with a corresponding correct output. The goal is for the algorithm to learn a mapping from inputs to outputs, allowing it to predict the output for new, unseen inputs. Examples include:</p>
        <ul class="list-outside">
            <li class="text-s md:text-s max-w-[min(56rem,90%)] mx-auto"><strong>Classification:</strong> Predicting a categorical output, such as whether an email is spam or not spam (binary classification), or classifying images into different object categories (multi-class classification). Common algorithms include Logistic Regression, Support Vector Machines (SVMs), Decision Trees, Random Forests, and Neural Networks.</li>
            <li class="text-s md:text-s max-w-[min(56rem,90%)] mx-auto"><strong>Regression:</strong> Predicting a continuous numerical output, such as house prices based on features like size and location, or predicting stock market trends. Algorithms like Linear Regression, Polynomial Regression, and various tree-based models are often used.</li>
        </ul>
        <br/><p class="text-s md:text-s max-w-[min(56rem,90%)] mx-auto">The development and deployment of machine learning models involve several stages. It begins with data preparation, which includes collecting, cleaning, and preprocessing the data. Feature engineering, the process of selecting, transforming, and creating relevant features from raw data, is often a critical step that significantly impacts model performance. Next, the appropriate ML algorithm is chosen, and the data is split into training and testing sets. The model is trained on the training data, and its performance is evaluated on the unseen test data to assess its generalization ability and avoid overfitting. Hyperparameter tuning, cross-validation, and model selection are iterative processes to optimize model performance.</p>
        <br/><p class="text-s md:text-s max-w-[min(56rem,90%)] mx-auto">The power of machine learning is significantly amplified by deep learning, a subfield of ML that uses artificial neural networks with multiple layers (hence "deep"). Deep learning models, particularly Convolutional Neural Networks (CNNs) for image data and Recurrent Neural Networks (RNNs) or Transformers for sequential data like text, have achieved state-of-the-art results in complex tasks previously considered intractable for computers, such as image recognition, natural language understanding, and speech synthesis.</p>
        <br/><p class="text-s md:text-s max-w-[min(56rem,90%)] mx-auto">Despite its transformative potential, machine learning presents challenges. Data bias can lead to discriminatory outcomes, interpretability remains an issue for complex models (leading to the emergence of Explainable AI), and computational resources can be substantial. Ethical considerations, privacy concerns, and the need for robust evaluation metrics are paramount to ensure responsible and beneficial deployment of machine learning systems, paving the way for a future where intelligent machines augment human capabilities and solve some of the world's most pressing problems.</p>
        <a href='/model' class="bg-purple-500 hover:bg-purple-600 text-white px-8 py-2 my-8 rounded-md font-medium">Try Machine Learning</a>
    </section>
    <section class="my-8 flex flex-col items-center max-w-[90%] mx-auto">
        <h3 class="text-2xl font-bold text-center my-4">Explainable AI</h3>
        <p class="text-s md:text-s max-w-4xl mx-auto">As machine learning models, particularly deep learning networks, become increasingly complex and are deployed in critical domains like healthcare, finance, and criminal justice, a significant challenge has emerged: their lack of transparency. Many powerful AI models operate as "black boxes," making decisions or predictions without providing clear, human-understandable justifications for their outputs. This opacity can hinder trust, accountability, and the ability to debug or improve these systems. This is precisely where Explainable AI (XAI) comes into play.</p>
        <br/><p class="text-s md:text-s max-w-4xl mx-auto">Explainable AI is a burgeoning field within AI research that aims to develop methods and techniques to make AI models more understandable and transparent to humans. The goal of XAI is not to replace the AI model itself but to provide insights into its inner workings, reasoning, and decision-making processes. This includes understanding why a model made a specific prediction, what features it considered most important, and under what conditions it might fail.</p>
        <br/><p class="text-s md:text-s max-w-4xl mx-auto">The necessity for Explainable AI (XAI) arises from several critical factors: it fosters trust among users and stakeholders, ensures accountability and compliance in regulated sectors, aids developers in debugging and improving model performance, addresses ethical concerns by identifying and mitigating biases, and ultimately promotes broader user adoption by providing clarity into AI's operations.</p>
        <img src="/static/images/xai.png" alt="explainable ai illustration" width="270">
        <br/><p class="text-s md:text-s max-w-4xl mx-auto">In the realm of XAI, explanations can be broadly categorized as either global or local, each offering a distinct perspective on a model's behavior.</p>
        <ul class="list-outside">
            <li class="text-s md:text-s max-w-4xl mx-auto"><strong>Global explanations</strong> aim to provide an overarching understanding of how a model makes predictions across its entire dataset. They seek to reveal the general relationships and patterns the model has learned. For instance, a global explanation might tell you which features are generally most important for a model's predictions, or how the model's output typically changes with variations in certain inputs. These explanations are valuable for understanding the model's general logic, identifying potential biases that affect broad groups, and gaining insights into the underlying domain relationships that the model has captured. However, a global explanation might not fully capture the nuances of a specific individual prediction, as the model's behavior can be complex and non-linear.</li>
            <li class="text-s md:text-s max-w-4xl mx-auto"><strong>Local explanations</strong>, on the other hand, focus on explaining a single, specific prediction made by the model. They delve into why the model arrived at a particular output for a given input instance. For example, if a model predicts that a loan applicant is high-risk, a local explanation would detail which specific factors in that applicant's profile contributed most to that particular high-risk assessment. Local explanations are crucial for building trust in individual decisions, justifying outcomes to affected parties, and diagnosing issues related to specific cases. They provide a precise attribution of the model's decision for a particular instance, even if the model's global behavior is highly intricate.</li>
        </ul>
        <br/><p class="text-s md:text-s max-w-4xl mx-auto">The development of XAI is an ongoing challenge, requiring a balance between model complexity, predictive performance, and interpretability. The effectiveness of an explanation also depends on the target audience – an explanation for a data scientist will differ from one intended for a domain expert or a general user.Ultimately, Explainable AI is not just a technical pursuit; it's a societal imperative. As AI becomes more pervasive and influential in our lives, the ability to understand, question, and ultimately trust these intelligent systems will be paramount to their responsible development and deployment, ensuring that AI serves humanity in a transparent, fair, and beneficial manner.</p>
        <a href='/explain' class="bg-purple-500 hover:bg-purple-600 text-white px-8 py-2 my-8 rounded-md font-medium">Try Explainable AI</a>
    </section>

{% endblock %}